{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dceb495-d0a1-4c61-8024-c3b18641fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c835deda-7aca-42dc-87d8-ff067c440c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_Features=pd.read_csv('tox21_global_cdf_rdkit.csv')\n",
    "initial_dataset=pd.read_csv('tox21.csv')\n",
    "initial_Features=initial_Features.loc[:,initial_Features.apply(pd.Series.nunique) != 1]\n",
    "initial_dataset=initial_dataset.iloc[initial_Features.dropna().index]\n",
    "initial_dataset=initial_dataset.reset_index()\n",
    "initial_Features=initial_Features.dropna()\n",
    "initial_Features=initial_Features.reset_index()\n",
    "index_array=[]\n",
    "for i in np.arange(1,13):\n",
    "    index_array.append(initial_dataset.iloc[:,i+1].dropna().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfc0a79-9791-44a0-b1e7-b0f19e28ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_ith(i):\n",
    "    return pd.DataFrame(data=initial_dataset.iloc[index_array[i]].iloc[:,i+2])\n",
    "def Feature_ith(i):\n",
    "    return initial_Features.iloc[index_array[i]].drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2dd0835-ea1a-44c4-8056-c36aa6ab58f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA with 71 principal components retains 95.14902477458284 % of data VAR. (It is related for 0 th label)\n",
      "PCA with 71 principal components retains 95.18528509261213 % of data VAR. (It is related for 1 th label)\n",
      "PCA with 71 principal components retains 95.23516716185081 % of data VAR. (It is related for 2 th label)\n",
      "PCA with 71 principal components retains 95.24899205532745 % of data VAR. (It is related for 3 th label)\n",
      "PCA with 71 principal components retains 95.19568949095981 % of data VAR. (It is related for 4 th label)\n",
      "PCA with 71 principal components retains 95.18825061528679 % of data VAR. (It is related for 5 th label)\n",
      "PCA with 71 principal components retains 95.13894464393015 % of data VAR. (It is related for 6 th label)\n",
      "PCA with 71 principal components retains 95.21618305641543 % of data VAR. (It is related for 7 th label)\n",
      "PCA with 71 principal components retains 95.18018989506741 % of data VAR. (It is related for 8 th label)\n",
      "PCA with 71 principal components retains 95.16545227328498 % of data VAR. (It is related for 9 th label)\n",
      "PCA with 71 principal components retains 95.22548243540908 % of data VAR. (It is related for 10 th label)\n",
      "PCA with 71 principal components retains 95.17820123387547 % of data VAR. (It is related for 11 th label)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_training_data=[]\n",
    "X_test=[]\n",
    "y_training_data=[]\n",
    "y_test=[]\n",
    "for i in np.arange(0,12):\n",
    "    X_training_data_tmp, X_test_tmp, y_training_data_tmp, y_test_tmp =train_test_split(Feature_ith(i),label_ith(i), stratify=label_ith(i),test_size=0.10,random_state=1234)\n",
    "    X_training_data.append(X_training_data_tmp)\n",
    "    X_test.append(X_test_tmp)\n",
    "    y_training_data.append(y_training_data_tmp)\n",
    "    y_test.append(y_test_tmp)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "X_training_data_pca=[]\n",
    "X_test_pca=[]\n",
    "for i in np.arange(0,12):\n",
    "    pca = PCA(n_components=71)\n",
    "    principalComponents = pca.fit_transform(X_training_data[i])\n",
    "    X_training_data_PCA_tmp = pd.DataFrame(data = principalComponents)\n",
    "    X_training_data_pca.append(X_training_data_PCA_tmp)\n",
    "    X_test_pca_tmp=pd.DataFrame(data=pca.transform(X_test[i]))\n",
    "    X_test_pca.append(X_test_pca_tmp)\n",
    "    print('PCA with 71 principal components retains',np.sum(pca.explained_variance_ratio_)*100,'% of data VAR. (It is related for',i,'th label)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c258cc32-fd05-458b-802f-8133ea1ac0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a240b94-076a-47dc-919e-bee48c73fd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier:\n",
      "-----------------------This information is for the  0 th label.-----------------------\n",
      "-------------------------------------Including PCA.-------------------------------------\n",
      "best mean cv score=  0.7235540265998088\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 7}\n",
      "[[682   4]\n",
      " [ 15  16]]\n",
      "0.7551490642339885\n",
      "-----------------------This information is for the  1 th label.-----------------------\n",
      "-------------------------------------Including PCA.-------------------------------------\n",
      "best mean cv score=  0.7850023245692129\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 1}\n",
      "[[637   9]\n",
      " [  6  17]]\n",
      "0.8625992731188585\n",
      "-----------------------This information is for the  2 th label.-----------------------\n",
      "-------------------------------------Including PCA.-------------------------------------\n",
      "best mean cv score=  0.7259460692370788\n",
      "best parameters=  {'metric': 'cosine', 'n_neighbors': 1}\n",
      "[[544  27]\n",
      " [ 33  44]]\n",
      "0.7620715536652489\n",
      "-----------------------This information is for the  3 th label.-----------------------\n",
      "-------------------------------------Including PCA.-------------------------------------\n",
      "best mean cv score=  0.6768973816233019\n",
      "best parameters=  {'metric': 'cosine', 'n_neighbors': 1}\n",
      "[[530  17]\n",
      " [ 13  17]]\n",
      "0.767794028031688\n",
      "-----------------------This information is for the  4 th label.-----------------------\n",
      "-------------------------------------Including PCA.-------------------------------------\n",
      "best mean cv score=  0.639949171815369\n",
      "best parameters=  {'metric': 'euclidean', 'n_neighbors': 3}\n",
      "[[512  22]\n",
      " [ 58  21]]\n",
      "0.6123121414687337\n",
      "-----------------------This information is for the  5 th label.-----------------------\n",
      "-------------------------------------Including PCA.-------------------------------------\n",
      "best mean cv score=  0.7037870122495336\n",
      "best parameters=  {'metric': 'euclidean', 'n_neighbors': 1}\n",
      "[[636  18]\n",
      " [ 20  13]]\n",
      "0.6832082290797887\n",
      "-----------------------This information is for the  6 th label.-----------------------\n",
      "-------------------------------------Including PCA.-------------------------------------\n",
      "best mean cv score=  0.5970295738998852\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 1}\n",
      "[[613   8]\n",
      " [ 11   6]]\n",
      "0.670029364402766\n",
      "-----------------------This information is for the  7 th label.-----------------------\n",
      "-------------------------------------Including PCA.-------------------------------------\n",
      "best mean cv score=  0.6628518308101344\n",
      "best parameters=  {'metric': 'cosine', 'n_neighbors': 1}\n",
      "[[431  55]\n",
      " [ 45  46]]\n",
      "0.696162890607335\n",
      "-----------------------This information is for the  8 th label.-----------------------\n",
      "-------------------------------------Including PCA.-------------------------------------\n",
      "best mean cv score=  0.6327067238634185\n",
      "best parameters=  {'metric': 'euclidean', 'n_neighbors': 1}\n",
      "[[660  15]\n",
      " [ 17   8]]\n",
      "0.6488888888888888\n",
      "-----------------------This information is for the  9 th label.-----------------------\n",
      "-------------------------------------Including PCA.-------------------------------------\n",
      "best mean cv score=  0.6296254938216598\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 1}\n",
      "[[578  26]\n",
      " [ 22  13]]\n",
      "0.6641911069063386\n",
      "-----------------------This information is for the  10 th label.-----------------------\n",
      "-------------------------------------Including PCA.-------------------------------------\n",
      "best mean cv score=  0.7639088766366591\n",
      "best parameters=  {'metric': 'cosine', 'n_neighbors': 1}\n",
      "[[443  41]\n",
      " [ 32  58]]\n",
      "0.7798668503213958\n",
      "-----------------------This information is for the  11 th label.-----------------------\n",
      "-------------------------------------Including PCA.-------------------------------------\n",
      "best mean cv score=  0.6857203682733718\n",
      "best parameters=  {'metric': 'cosine', 'n_neighbors': 1}\n",
      "[[608  21]\n",
      " [ 23  18]]\n",
      "0.7028190313699639\n"
     ]
    }
   ],
   "source": [
    "print(\"KNeighborsClassifier:\")\n",
    "for i in np.arange(0,12,1):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier()\n",
    "    param_grid={'n_neighbors':np.arange(1,11,2),'metric':['euclidean','cosine','manhattan']}\n",
    "    grid=GridSearchCV(knn,param_grid=param_grid,cv=10,scoring='balanced_accuracy',return_train_score=False)\n",
    "    grid.fit(X_training_data_pca[i].to_numpy(),y_training_data[i])\n",
    "    print(\"-----------------------This information is for the \",i,\"th label.-----------------------\")\n",
    "    print(\"-------------------------------------Including PCA.-------------------------------------\")\n",
    "    print(\"best mean cv score= \",grid.best_score_)\n",
    "    print(\"best parameters= \",grid.best_params_)\n",
    "    y_pred_knn_pca=grid.best_estimator_.predict(X_test_pca[i])\n",
    "    print(confusion_matrix(y_test[i],np.transpose(np.matrix(y_pred_knn_pca))))\n",
    "    print(grid.score(X_test_pca[i],y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8453994-018b-4d8b-9e58-415399b63396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier:\n",
      "-----------------------This information is for the  0 th label.-----------------------\n",
      "best mean cv score=  0.7309100650238083\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 9}\n",
      "[[683   3]\n",
      " [ 15  16]]\n",
      "0.7558779272077494\n",
      "-----------------------This information is for the  1 th label.-----------------------\n",
      "best mean cv score=  0.7846450333353117\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 1}\n",
      "[[634  12]\n",
      " [  6  17]]\n",
      "0.8602772916947099\n",
      "-----------------------This information is for the  2 th label.-----------------------\n",
      "best mean cv score=  0.7272648019793841\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 1}\n",
      "[[545  26]\n",
      " [ 32  45]]\n",
      "0.7694407169013123\n",
      "-----------------------This information is for the  3 th label.-----------------------\n",
      "best mean cv score=  0.6781417541315211\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 1}\n",
      "[[528  19]\n",
      " [ 13  17]]\n",
      "0.7659658744667885\n",
      "-----------------------This information is for the  4 th label.-----------------------\n",
      "best mean cv score=  0.6430757718521802\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 3}\n",
      "[[505  29]\n",
      " [ 59  20]]\n",
      "0.5994287204285782\n",
      "-----------------------This information is for the  5 th label.-----------------------\n",
      "best mean cv score=  0.7049780678881433\n",
      "best parameters=  {'metric': 'euclidean', 'n_neighbors': 1}\n",
      "[[637  17]\n",
      " [ 20  13]]\n",
      "0.6839727550736725\n",
      "-----------------------This information is for the  6 th label.-----------------------\n",
      "best mean cv score=  0.6020852568911459\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 1}\n",
      "[[611  10]\n",
      " [ 11   6]]\n",
      "0.6684190584446339\n",
      "-----------------------This information is for the  7 th label.-----------------------\n",
      "best mean cv score=  0.6631432384485604\n",
      "best parameters=  {'metric': 'cosine', 'n_neighbors': 1}\n",
      "[[434  52]\n",
      " [ 45  46]]\n",
      "0.6992493103604215\n",
      "-----------------------This information is for the  8 th label.-----------------------\n",
      "best mean cv score=  0.6377311937912507\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 1}\n",
      "[[660  15]\n",
      " [ 19   6]]\n",
      "0.6088888888888888\n",
      "-----------------------This information is for the  9 th label.-----------------------\n",
      "best mean cv score=  0.6371383700958552\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 1}\n",
      "[[579  25]\n",
      " [ 23  12]]\n",
      "0.6507332071901608\n",
      "-----------------------This information is for the  10 th label.-----------------------\n",
      "best mean cv score=  0.7758465460133529\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 1}\n",
      "[[447  37]\n",
      " [ 31  59]]\n",
      "0.78955463728191\n",
      "-----------------------This information is for the  11 th label.-----------------------\n",
      "best mean cv score=  0.6895577029999881\n",
      "best parameters=  {'metric': 'manhattan', 'n_neighbors': 1}\n",
      "[[610  19]\n",
      " [ 22  19]]\n",
      "0.7166039784404203\n"
     ]
    }
   ],
   "source": [
    "print(\"KNeighborsClassifier:\")\n",
    "for i in np.arange(0,12,1):\n",
    "    knn = KNeighborsClassifier()\n",
    "    param_grid={'n_neighbors':np.arange(1,11,2),'metric':['euclidean','cosine','manhattan']}\n",
    "    grid=GridSearchCV(knn,param_grid=param_grid,cv=10,scoring='balanced_accuracy',return_train_score=False)\n",
    "    grid.fit(X_training_data[i].to_numpy(),y_training_data[i])\n",
    "    print(\"-----------------------This information is for the \",i,\"th label.-----------------------\")\n",
    "    #print(\"-------------------------------------Including PCA.-------------------------------------\")\n",
    "    print(\"best mean cv score= \",grid.best_score_)\n",
    "    print(\"best parameters= \",grid.best_params_)\n",
    "    y_pred_knn=grid.best_estimator_.predict(X_test[i])\n",
    "    print(confusion_matrix(y_test[i],np.transpose(np.matrix(y_pred_knn))))\n",
    "    print(grid.score(X_test[i],y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "667b77b0-a839-476c-b5e2-0c59c3f5057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier:\n",
      "-----------------------This information is for the  0 th label.----------------------------\n",
      "best mean cv score=  0.7343343187519519\n",
      "best parameters=  {'criterion': 'entropy', 'max_depth': 4}\n",
      "[[682   4]\n",
      " [ 15  16]]\n",
      "0.7551490642339885\n",
      "-----------------------This information is for the  1 th label.----------------------------\n",
      "best mean cv score=  0.7493516924842225\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 27}\n",
      "[[637   9]\n",
      " [  7  16]]\n",
      "0.8408601426840758\n",
      "-----------------------This information is for the  2 th label.----------------------------\n",
      "best mean cv score=  0.715454431723965\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 27}\n",
      "[[534  37]\n",
      " [ 34  43]]\n",
      "0.7468214797461732\n",
      "-----------------------This information is for the  3 th label.----------------------------\n",
      "best mean cv score=  0.6357916597143412\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 22}\n",
      "[[523  24]\n",
      " [ 19  11]]\n",
      "0.6613954905545399\n",
      "-----------------------This information is for the  4 th label.----------------------------\n",
      "best mean cv score=  0.6307871144050721\n",
      "best parameters=  {'criterion': 'entropy', 'max_depth': 13}\n",
      "[[487  47]\n",
      " [ 53  26]]\n",
      "0.6205494713886124\n",
      "-----------------------This information is for the  5 th label.----------------------------\n",
      "best mean cv score=  0.6988894876519602\n",
      "best parameters=  {'criterion': 'entropy', 'max_depth': 28}\n",
      "[[627  27]\n",
      " [ 23  10]]\n",
      "0.6308729496802892\n",
      "-----------------------This information is for the  6 th label.----------------------------\n",
      "best mean cv score=  0.5994250886439558\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 28}\n",
      "[[607  14]\n",
      " [ 10   7]]\n",
      "0.6946102112342522\n",
      "-----------------------This information is for the  7 th label.----------------------------\n",
      "best mean cv score=  0.6527794346669296\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 21}\n",
      "[[431  55]\n",
      " [ 53  38]]\n",
      "0.6522068466512911\n",
      "-----------------------This information is for the  8 th label.----------------------------\n",
      "best mean cv score=  0.617416934552133\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 28}\n",
      "[[652  23]\n",
      " [ 18   7]]\n",
      "0.6229629629629629\n",
      "-----------------------This information is for the  9 th label.----------------------------\n",
      "best mean cv score=  0.6111641916613375\n",
      "best parameters=  {'criterion': 'entropy', 'max_depth': 21}\n",
      "[[575  29]\n",
      " [ 24  11]]\n",
      "0.6331362346263009\n",
      "-----------------------This information is for the  10 th label.----------------------------\n",
      "best mean cv score=  0.7517233591876147\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 20}\n",
      "[[448  36]\n",
      " [ 37  53]]\n",
      "0.7572543617998164\n",
      "-----------------------This information is for the  11 th label.----------------------------\n",
      "best mean cv score=  0.6584764787503303\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 28}\n",
      "[[589  40]\n",
      " [ 28  13]]\n",
      "0.6267400829811159\n"
     ]
    }
   ],
   "source": [
    "print(\"DecisionTreeClassifier:\")\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "for i in np.arange(0,12,1):\n",
    "    DecisionTree = DecisionTreeClassifier()\n",
    "    param_grid={'criterion':['gini','entropy'],'max_depth':np.arange(4,30,1)}\n",
    "    grid=GridSearchCV(DecisionTree,param_grid=param_grid,cv=10,scoring='balanced_accuracy',return_train_score=False)\n",
    "    grid.fit(X_training_data[i].to_numpy(),y_training_data[i])\n",
    "    print(\"-----------------------This information is for the \",i,\"th label.----------------------------\")\n",
    "    print(\"best mean cv score= \",grid.best_score_)\n",
    "    print(\"best parameters= \",grid.best_params_)\n",
    "    y_pred_dt=grid.best_estimator_.predict(X_test[i])\n",
    "    print(confusion_matrix(y_test[i],np.transpose(np.matrix(y_pred_dt))))\n",
    "    print(grid.score(X_test[i],y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9703456e-fa97-46e4-a14a-1e9005ff6749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier:\n",
      "-----------------------This information is for the  0 th label.----------------------------\n",
      "best mean cv score=  0.7216258089347315\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 15, 'max_features': 'auto', 'n_estimators': 700}\n",
      "[[684   2]\n",
      " [ 15  16]]\n",
      "0.7566067901815103\n",
      "-----------------------This information is for the  1 th label.----------------------------\n",
      "best mean cv score=  0.739999752677349\n",
      "best parameters=  {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "[[640   6]\n",
      " [  6  17]]\n",
      "0.8649212545430072\n",
      "-----------------------This information is for the  2 th label.----------------------------\n",
      "best mean cv score=  0.6722003183198237\n",
      "best parameters=  {'criterion': 'entropy', 'max_depth': 20, 'max_features': 'auto', 'n_estimators': 700}\n",
      "[[560  11]\n",
      " [ 46  31]]\n",
      "0.6916664771305752\n",
      "-----------------------This information is for the  3 th label.----------------------------\n",
      "best mean cv score=  0.5665454586815841\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "[[544   3]\n",
      " [ 20  10]]\n",
      "0.6639244363193175\n",
      "-----------------------This information is for the  4 th label.----------------------------\n",
      "best mean cv score=  0.6182522327025808\n",
      "best parameters=  {'criterion': 'entropy', 'max_depth': 20, 'max_features': 'auto', 'n_estimators': 500}\n",
      "[[526   8]\n",
      " [ 57  22]]\n",
      "0.631749869624994\n",
      "-----------------------This information is for the  5 th label.----------------------------\n",
      "best mean cv score=  0.6767173252279635\n",
      "best parameters=  {'criterion': 'entropy', 'max_depth': 15, 'max_features': 'auto', 'n_estimators': 500}\n",
      "[[652   2]\n",
      " [ 23  10]]\n",
      "0.649986099527384\n",
      "-----------------------This information is for the  6 th label.----------------------------\n",
      "best mean cv score=  0.509426763957477\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 20, 'max_features': 'auto', 'n_estimators': 500}\n",
      "[[621   0]\n",
      " [ 17   0]]\n",
      "0.5\n",
      "-----------------------This information is for the  7 th label.----------------------------\n",
      "best mean cv score=  0.5917580102590566\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "[[480   6]\n",
      " [ 61  30]]\n",
      "0.6586623253289919\n",
      "-----------------------This information is for the  8 th label.----------------------------\n",
      "best mean cv score=  0.5349558244652022\n",
      "best parameters=  {'criterion': 'entropy', 'max_depth': 20, 'max_features': 'auto', 'n_estimators': 500}\n",
      "[[674   1]\n",
      " [ 23   2]]\n",
      "0.5392592592592592\n",
      "-----------------------This information is for the  9 th label.----------------------------\n",
      "best mean cv score=  0.5541034155597723\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 20, 'max_features': 'auto', 'n_estimators': 500}\n",
      "[[603   1]\n",
      " [ 30   5]]\n",
      "0.570600756859035\n",
      "-----------------------This information is for the  10 th label.----------------------------\n",
      "best mean cv score=  0.7399732819343566\n",
      "best parameters=  {'criterion': 'gini', 'max_depth': 20, 'max_features': 'auto', 'n_estimators': 500}\n",
      "[[469  15]\n",
      " [ 41  49]]\n",
      "0.7567263544536271\n",
      "-----------------------This information is for the  11 th label.----------------------------\n",
      "best mean cv score=  0.5619639353507783\n",
      "best parameters=  {'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "[[628   1]\n",
      " [ 35   6]]\n",
      "0.5723758191476986\n"
     ]
    }
   ],
   "source": [
    "print(\"RandomForestClassifier:\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "for i in np.arange(0,12,1):\n",
    "    RFC = RandomForestClassifier()\n",
    "    param_grid={'n_estimators':[500,700],'criterion':['gini','entropy'],'max_depth':[4,6,8,10,15,20], 'max_features':['auto','sqrt','log2']}\n",
    "    grid=GridSearchCV(RFC,param_grid=param_grid,cv=5,scoring='balanced_accuracy',return_train_score=False)\n",
    "    grid.fit(X_training_data[i].to_numpy(),y_training_data[i])\n",
    "    print(\"-----------------------This information is for the \",i,\"th label.----------------------------\")\n",
    "    print(\"best mean cv score= \",grid.best_score_)\n",
    "    print(\"best parameters= \",grid.best_params_)\n",
    "    y_pred_RFC=grid.best_estimator_.predict(X_test[i])\n",
    "    print(confusion_matrix(y_test[i],np.transpose(np.matrix(y_pred_RFC))))\n",
    "    print(grid.score(X_test[i],y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2c57e21-ea52-4ecc-b6b4-aa8d8085fd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier:\n",
      "-----------------------This information is for the  0 th label.----------------------------\n",
      "best mean cv score=  0.7220923302944042\n",
      "best parameters=  {'eval_metric': 'mlogloss', 'max_depth': 3, 'n_estimators': 700}\n",
      "[[683   3]\n",
      " [ 16  15]]\n",
      "0.7397488949496849\n",
      "-----------------------This information is for the  1 th label.----------------------------\n",
      "best mean cv score=  0.7588862345935466\n",
      "best parameters=  {'eval_metric': 'mlogloss', 'max_depth': 6, 'n_estimators': 2000}\n",
      "[[640   6]\n",
      " [  8  15]]\n",
      "0.821442993673442\n",
      "-----------------------This information is for the  2 th label.----------------------------\n",
      "best mean cv score=  0.7333850964654818\n",
      "best parameters=  {'eval_metric': 'mlogloss', 'max_depth': 5, 'n_estimators': 2000}\n",
      "[[557  14]\n",
      " [ 36  41]]\n",
      "0.7539745718379693\n",
      "-----------------------This information is for the  3 th label.----------------------------\n",
      "best mean cv score=  0.6181325689242583\n",
      "best parameters=  {'eval_metric': 'mlogloss', 'max_depth': 5, 'n_estimators': 700}\n",
      "[[540   7]\n",
      " [ 20  10]]\n",
      "0.6602681291895186\n",
      "-----------------------This information is for the  4 th label.----------------------------\n",
      "best mean cv score=  0.6417879130291102\n",
      "best parameters=  {'eval_metric': 'mlogloss', 'max_depth': 3, 'n_estimators': 2000}\n",
      "[[519  15]\n",
      " [ 54  25]]\n",
      "0.6441829042810412\n",
      "-----------------------This information is for the  5 th label.----------------------------\n",
      "best mean cv score=  0.6939448539211255\n",
      "best parameters=  {'eval_metric': 'mlogloss', 'max_depth': 7, 'n_estimators': 700}\n",
      "[[650   4]\n",
      " [ 22  11]]\n",
      "0.6636085626911314\n",
      "-----------------------This information is for the  6 th label.----------------------------\n",
      "best mean cv score=  0.5692212315899486\n",
      "best parameters=  {'eval_metric': 'mlogloss', 'max_depth': 3, 'n_estimators': 700}\n",
      "[[621   0]\n",
      " [ 16   1]]\n",
      "0.5294117647058824\n",
      "-----------------------This information is for the  7 th label.----------------------------\n",
      "best mean cv score=  0.6742232870501532\n",
      "best parameters=  {'eval_metric': 'mlogloss', 'max_depth': 5, 'n_estimators': 2000}\n",
      "[[462  24]\n",
      " [ 48  43]]\n",
      "0.7115723782390448\n",
      "-----------------------This information is for the  8 th label.----------------------------\n",
      "best mean cv score=  0.5970327471111124\n",
      "best parameters=  {'eval_metric': 'mlogloss', 'max_depth': 4, 'n_estimators': 700}\n",
      "[[669   6]\n",
      " [ 21   4]]\n",
      "0.5755555555555556\n",
      "-----------------------This information is for the  9 th label.----------------------------\n",
      "best mean cv score=  0.5932812079563602\n",
      "best parameters=  {'eval_metric': 'mlogloss', 'max_depth': 6, 'n_estimators': 700}\n",
      "[[601   3]\n",
      " [ 27   8]]\n",
      "0.611802270577105\n",
      "-----------------------This information is for the  10 th label.----------------------------\n",
      "best mean cv score=  0.7958197053234901\n",
      "best parameters=  {'eval_metric': 'mlogloss', 'max_depth': 3, 'n_estimators': 700}\n",
      "[[462  22]\n",
      " [ 33  57]]\n",
      "0.793939393939394\n",
      "-----------------------This information is for the  11 th label.----------------------------\n",
      "best mean cv score=  0.619645691038506\n",
      "best parameters=  {'eval_metric': 'mlogloss', 'max_depth': 3, 'n_estimators': 700}\n",
      "[[624   5]\n",
      " [ 30  11]]\n",
      "0.6301717786653225\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "print(\"XGBClassifier:\")\n",
    "for i in np.arange(0,12,1):\n",
    "    param_grid={'n_estimators':[700,2000],'max_depth':[3,4,5,6,7],'eval_metric':['mlogloss']}\n",
    "    grid=GridSearchCV(XGBClassifier(),param_grid=param_grid,cv=10,scoring='balanced_accuracy',return_train_score=False)\n",
    "    grid.fit(X_training_data[i].to_numpy(),y_training_data[i])\n",
    "    print(\"-----------------------This information is for the \",i,\"th label.----------------------------\")\n",
    "    print(\"best mean cv score= \",grid.best_score_)\n",
    "    print(\"best parameters= \",grid.best_params_)\n",
    "    y_pred_xgbc=grid.best_estimator_.predict(X_test[i])\n",
    "    print(confusion_matrix(y_test[i],np.transpose(np.matrix(y_pred_xgbc))))\n",
    "    print(grid.score(X_test[i],y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2258c912-e410-4633-8f36-73dcf9bd4dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier:\n",
      "-----------------------This information is for the  0 th label.----------------------------\n",
      "best mean cv score=  0.7230681963217643\n",
      "best parameters=  {'degree': 4, 'kernel': 'poly'}\n",
      "[[680   6]\n",
      " [ 15  16]]\n",
      "0.7536913382864667\n",
      "-----------------------This information is for the  1 th label.----------------------------\n",
      "best mean cv score=  0.7546105110095553\n",
      "best parameters=  {'degree': 5, 'kernel': 'poly'}\n",
      "[[638   8]\n",
      " [  8  15]]\n",
      "0.8198950060573429\n",
      "-----------------------This information is for the  2 th label.----------------------------\n",
      "best mean cv score=  0.7242156849858815\n",
      "best parameters=  {'degree': 5, 'kernel': 'poly'}\n",
      "[[546  25]\n",
      " [ 38  39]]\n",
      "0.7313553346828303\n",
      "-----------------------This information is for the  3 th label.----------------------------\n",
      "best mean cv score=  0.6645036425232391\n",
      "best parameters=  {'degree': 7, 'kernel': 'poly'}\n",
      "[[534  13]\n",
      " [ 17  13]]\n",
      "0.7047836684948202\n",
      "-----------------------This information is for the  4 th label.----------------------------\n",
      "best mean cv score=  0.630630697298831\n",
      "best parameters=  {'degree': 11, 'kernel': 'poly'}\n",
      "[[490  44]\n",
      " [ 56  23]]\n",
      "0.6043711183805054\n",
      "-----------------------This information is for the  5 th label.----------------------------\n",
      "best mean cv score=  0.6947422904425824\n",
      "best parameters=  {'degree': 8, 'kernel': 'poly'}\n",
      "[[645   9]\n",
      " [ 20  13]]\n",
      "0.6900889630247429\n",
      "-----------------------This information is for the  6 th label.----------------------------\n",
      "best mean cv score=  0.5878664257410506\n",
      "best parameters=  {'degree': 9, 'kernel': 'poly'}\n",
      "[[612   9]\n",
      " [ 11   6]]\n",
      "0.6692242114236999\n",
      "-----------------------This information is for the  7 th label.----------------------------\n",
      "best mean cv score=  0.6656936034198049\n",
      "best parameters=  {'degree': 14, 'kernel': 'poly'}\n",
      "[[433  53]\n",
      " [ 54  37]]\n",
      "0.6487699543255099\n",
      "-----------------------This information is for the  8 th label.----------------------------\n",
      "best mean cv score=  0.5954265276466763\n",
      "best parameters=  {'degree': 10, 'kernel': 'poly'}\n",
      "[[667   8]\n",
      " [ 18   7]]\n",
      "0.634074074074074\n",
      "-----------------------This information is for the  9 th label.----------------------------\n",
      "best mean cv score=  0.6096192244051426\n",
      "best parameters=  {'degree': 10, 'kernel': 'poly'}\n",
      "[[583  21]\n",
      " [ 24  11]]\n",
      "0.6397587511825922\n",
      "-----------------------This information is for the  10 th label.----------------------------\n",
      "best mean cv score=  0.7740261034794257\n",
      "best parameters=  {'degree': 5, 'kernel': 'poly'}\n",
      "[[454  30]\n",
      " [ 36  54]]\n",
      "0.7690082644628099\n",
      "-----------------------This information is for the  11 th label.----------------------------\n",
      "best mean cv score=  0.6622435935009551\n",
      "best parameters=  {'degree': 7, 'kernel': 'poly'}\n",
      "[[618  11]\n",
      " [ 24  17]]\n",
      "0.6985730350149288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "print(\"SVC:\")\n",
    "for i in np.arange(0,12,1):\n",
    "    param_grid={'kernel':['poly'],'degree':np.arange(1,15,1)}\n",
    "    grid=GridSearchCV(SVC(),param_grid=param_grid,cv=10,scoring='balanced_accuracy',return_train_score=False)\n",
    "    grid.fit(X_training_data[i].to_numpy(),y_training_data[i])\n",
    "    print(\"-----------------------This information is for the \",i,\"th label.----------------------------\")\n",
    "    print(\"best mean cv score= \",grid.best_score_)\n",
    "    print(\"best parameters= \",grid.best_params_)\n",
    "    y_pred_svm=grid.best_estimator_.predict(X_test[i])\n",
    "    print(confusion_matrix(y_test[i],np.transpose(np.matrix(y_pred_svm))))\n",
    "    print(grid.score(X_test[i],y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20627dbb-3675-4e98-8a3c-3be49801244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier:\n",
      "-----------------------This information is for the  0 th label.----------------------------\n",
      "best mean cv score=  0.7157613477540118\n",
      "best parameters=  {'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 8000}\n",
      "[[674  12]\n",
      " [ 16  15]]\n",
      "0.7331891281858365\n",
      "-----------------------This information is for the  1 th label.----------------------------\n",
      "best mean cv score=  0.7341166085078775\n",
      "best parameters=  {'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 500}\n",
      "[[640   6]\n",
      " [  6  17]]\n",
      "0.8649212545430072\n",
      "-----------------------This information is for the  2 th label.----------------------------\n",
      "best mean cv score=  0.7308967630172937\n",
      "best parameters=  {'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 8000}\n",
      "[[535  36]\n",
      " [ 35  42]]\n",
      "0.7412036299952236\n",
      "-----------------------This information is for the  3 th label.----------------------------\n",
      "best mean cv score=  0.6154114251647196\n",
      "best parameters=  {'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 8000}\n",
      "[[534  13]\n",
      " [ 16  14]]\n",
      "0.7214503351614869\n",
      "-----------------------This information is for the  4 th label.----------------------------\n",
      "best mean cv score=  0.6233451764286004\n",
      "best parameters=  {'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 1000}\n",
      "[[511  23]\n",
      " [ 57  22]]\n",
      "0.6177049258047693\n",
      "-----------------------This information is for the  5 th label.----------------------------\n",
      "best mean cv score=  0.6699627297727602\n",
      "best parameters=  {'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 8000}\n",
      "[[643  11]\n",
      " [ 21  12]]\n",
      "0.6734083958854601\n",
      "-----------------------This information is for the  6 th label.----------------------------\n",
      "best mean cv score=  0.5620798156865388\n",
      "best parameters=  {'algorithm': 'SAMME', 'learning_rate': 1, 'n_estimators': 8000}\n",
      "[[617   4]\n",
      " [ 17   0]]\n",
      "0.4967793880837359\n",
      "-----------------------This information is for the  7 th label.----------------------------\n",
      "best mean cv score=  0.6537217100575029\n",
      "best parameters=  {'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 8000}\n",
      "[[432  54]\n",
      " [ 54  37]]\n",
      "0.6477411477411477\n",
      "-----------------------This information is for the  8 th label.----------------------------\n",
      "best mean cv score=  0.5969505584559676\n",
      "best parameters=  {'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 8000}\n",
      "[[658  17]\n",
      " [ 18   7]]\n",
      "0.6274074074074074\n",
      "-----------------------This information is for the  9 th label.----------------------------\n",
      "best mean cv score=  0.5858266150853018\n",
      "best parameters=  {'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 700}\n",
      "[[600   4]\n",
      " [ 29   6]]\n",
      "0.58240302743614\n",
      "-----------------------This information is for the  10 th label.----------------------------\n",
      "best mean cv score=  0.7804093635981373\n",
      "best parameters=  {'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 1000}\n",
      "[[458  26]\n",
      " [ 36  54]]\n",
      "0.7731404958677686\n",
      "-----------------------This information is for the  11 th label.----------------------------\n",
      "best mean cv score=  0.624099446415163\n",
      "best parameters=  {'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 1000}\n",
      "[[617  12]\n",
      " [ 32   9]]\n",
      "0.6002171468455543\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "print(\"AdaBoostClassifier:\")\n",
    "for i in np.arange(0,12,1):\n",
    "    param_grid={'n_estimators':[8000,1000,500,700],'algorithm':['SAMME.R','SAMME'],'learning_rate':[1]}\n",
    "    grid=GridSearchCV(AdaBoostClassifier(),param_grid=param_grid,cv=5,scoring='balanced_accuracy',return_train_score=False)\n",
    "    grid.fit(X_training_data[i].to_numpy(),y_training_data[i])\n",
    "    print(\"-----------------------This information is for the \",i,\"th label.----------------------------\")\n",
    "    print(\"best mean cv score= \",grid.best_score_)\n",
    "    print(\"best parameters= \",grid.best_params_)\n",
    "    y_pred_adaboost=grid.best_estimator_.predict(X_test[i])\n",
    "    print(confusion_matrix(y_test[i],np.transpose(np.matrix(y_pred_adaboost))))\n",
    "    print(grid.score(X_test[i],y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4849a32b-415a-4cc5-910f-23da5882f8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier:\n",
      "-----------------------This information is for the  0 th label.----------------------------\n",
      "best mean cv score=  0.7269508786019065\n",
      "best parameters=  {'max_features': 0.6, 'max_samples': 0.5, 'n_estimators': 500}\n",
      "[[683   3]\n",
      " [ 15  16]]\n",
      "0.7558779272077494\n",
      "-----------------------This information is for the  1 th label.----------------------------\n",
      "best mean cv score=  0.7326826795066174\n",
      "best parameters=  {'max_features': 0.8, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "[[640   6]\n",
      " [  8  15]]\n",
      "0.821442993673442\n",
      "-----------------------This information is for the  2 th label.----------------------------\n",
      "best mean cv score=  0.6652733608745625\n",
      "best parameters=  {'max_features': 0.6, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "[[560  11]\n",
      " [ 48  29]]\n",
      "0.6786794641435623\n",
      "-----------------------This information is for the  3 th label.----------------------------\n",
      "best mean cv score=  0.559236688270835\n",
      "best parameters=  {'max_features': 0.8, 'max_samples': 0.5, 'n_estimators': 500}\n",
      "[[545   2]\n",
      " [ 24   6]]\n",
      "0.5981718464351006\n",
      "-----------------------This information is for the  4 th label.----------------------------\n",
      "best mean cv score=  0.6169766928272998\n",
      "best parameters=  {'max_features': 0.6, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "[[524  10]\n",
      " [ 57  22]]\n",
      "0.629877210448964\n",
      "-----------------------This information is for the  5 th label.----------------------------\n",
      "best mean cv score=  0.6717171804892169\n",
      "best parameters=  {'max_features': 0.8, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "[[653   1]\n",
      " [ 20  13]]\n",
      "0.6962051709758132\n",
      "-----------------------This information is for the  6 th label.----------------------------\n",
      "best mean cv score=  0.5288716095018979\n",
      "best parameters=  {'max_features': 0.8, 'max_samples': 0.5, 'n_estimators': 10}\n",
      "[[621   0]\n",
      " [ 17   0]]\n",
      "0.5\n",
      "-----------------------This information is for the  7 th label.----------------------------\n",
      "best mean cv score=  0.5930241135390106\n",
      "best parameters=  {'max_features': 0.8, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "[[478   8]\n",
      " [ 62  29]]\n",
      "0.6511102066657621\n",
      "-----------------------This information is for the  8 th label.----------------------------\n",
      "best mean cv score=  0.529686773652454\n",
      "best parameters=  {'max_features': 0.8, 'max_samples': 0.5, 'n_estimators': 10}\n",
      "[[674   1]\n",
      " [ 24   1]]\n",
      "0.5192592592592592\n",
      "-----------------------This information is for the  9 th label.----------------------------\n",
      "best mean cv score=  0.5476517181011051\n",
      "best parameters=  {'max_features': 0.8, 'max_samples': 0.5, 'n_estimators': 500}\n",
      "[[603   1]\n",
      " [ 29   6]]\n",
      "0.5848864711447493\n",
      "-----------------------This information is for the  10 th label.----------------------------\n",
      "best mean cv score=  0.7392036815039424\n",
      "best parameters=  {'max_features': 0.8, 'max_samples': 0.5, 'n_estimators': 500}\n",
      "[[466  18]\n",
      " [ 42  48]]\n",
      "0.7480716253443527\n",
      "-----------------------This information is for the  11 th label.----------------------------\n",
      "best mean cv score=  0.5421860682323457\n",
      "best parameters=  {'max_features': 0.8, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "[[628   1]\n",
      " [ 35   6]]\n",
      "0.5723758191476986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "print(\"BaggingClassifier:\")\n",
    "for i in np.arange(0,12,1):\n",
    "    param_grid={'n_estimators':[10,100,500],'max_samples':[1,0.5],'max_features':[1,0.8,0.6]}\n",
    "    grid=GridSearchCV(BaggingClassifier(),param_grid=param_grid,cv=5,scoring='balanced_accuracy',return_train_score=False)\n",
    "    grid.fit(X_training_data[i].to_numpy(),y_training_data[i])\n",
    "    print(\"-----------------------This information is for the \",i,\"th label.----------------------------\")\n",
    "    print(\"best mean cv score= \",grid.best_score_)\n",
    "    print(\"best parameters= \",grid.best_params_)\n",
    "    y_pred_bag=grid.best_estimator_.predict(X_test[i])\n",
    "    print(confusion_matrix(y_test[i],np.transpose(np.matrix(y_pred_bag))))\n",
    "    print(grid.score(X_test[i],y_test[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
